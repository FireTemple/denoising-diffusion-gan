{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(seed=1024, resume=True, image_size=32, num_channels=3, centered=True, use_geometric=False, beta_min=0.1, beta_max=20.0, num_channels_dae=128, n_mlp=4, ch_mult=[1, 2, 2, 2], num_res_blocks=2, attn_resolutions=(16,), dropout=0.0, resamp_with_conv=True, conditional=True, fir=True, fir_kernel=[1, 3, 3, 1], skip_rescale=True, resblock_type='biggan', progressive='none', progressive_input='residual', progressive_combine='sum', embedding_type='positional', fourier_scale=16.0, not_use_tanh=False, exp='ddgan_edges2shoes_4_full', dataset='edges2shoes', nz=100, num_timesteps=4, z_emb_dim=256, t_emb_dim=256, batch_size=1, num_epoch=1000, ngf=64, lr_g=0.00016, lr_d=0.000125, beta1=0.5, beta2=0.9, no_lr_decay=False, use_ema=True, ema_decay=0.9999, r1_gamma=0.02, lazy_reg=15, save_content=True, save_content_every=50, save_ckpt_every=25, num_proc_node=1, num_process_per_node=1, node_rank=0, local_rank=0, master_address='127.0.0.1', world_size=1)\n"
     ]
    }
   ],
   "source": [
    "from score_sde.models.ncsnpp_generator_adagn import NCSNpp\n",
    "from argparse import Namespace\n",
    "\n",
    "# 手动创建 args 对象\n",
    "args = Namespace(\n",
    "    seed=1024,\n",
    "    resume=True,\n",
    "    image_size=32,\n",
    "    num_channels=3,\n",
    "    centered=True,\n",
    "    use_geometric=False,\n",
    "    beta_min=0.1,\n",
    "    beta_max=20.0,\n",
    "    num_channels_dae=128,\n",
    "    n_mlp=4,\n",
    "    ch_mult=[1, 2, 2, 2],\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=(16,),\n",
    "    dropout=0.0,\n",
    "    resamp_with_conv=True,\n",
    "    conditional=True,\n",
    "    fir=True,\n",
    "    fir_kernel=[1, 3, 3, 1],\n",
    "    skip_rescale=True,\n",
    "    resblock_type='biggan',\n",
    "    progressive='none',\n",
    "    progressive_input='residual',\n",
    "    progressive_combine='sum',\n",
    "    embedding_type='positional',\n",
    "    fourier_scale=16.0,\n",
    "    not_use_tanh=False,\n",
    "    exp='ddgan_edges2shoes_4_full',\n",
    "    dataset='edges2shoes',\n",
    "    nz=100,\n",
    "    num_timesteps=4,\n",
    "    z_emb_dim=256,\n",
    "    t_emb_dim=256,\n",
    "    batch_size=1,\n",
    "    num_epoch=1000,\n",
    "    ngf=64,\n",
    "    lr_g=0.00016,\n",
    "    lr_d=0.000125,\n",
    "    beta1=0.5,\n",
    "    beta2=0.9,\n",
    "    no_lr_decay=False,\n",
    "    use_ema=True,\n",
    "    ema_decay=0.9999,\n",
    "    r1_gamma=0.02,\n",
    "    lazy_reg=15,\n",
    "    save_content=True,\n",
    "    save_content_every=50,\n",
    "    save_ckpt_every=25,\n",
    "    num_proc_node=1,\n",
    "    num_process_per_node=1,\n",
    "    node_rank=0,\n",
    "    local_rank=0,\n",
    "    master_address='127.0.0.1',\n",
    "    world_size=1\n",
    ")\n",
    "\n",
    "# 使用手动创建的 args 对象\n",
    "print(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bohan/anaconda3/envs/ddgan_c/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets_prep.edges2shoes import Edge2Shoes\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dataset = Edge2Shoes(\"/mnt/c/Users/Public/Documents/Datasets/edge2shoes\", 1, 32, device=\"cuda:0\", split=\"train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "device = \"cuda:0\"\n",
    "netG = NCSNpp(args).to(device)\n",
    "ckpt = torch.load('/mnt/c/Users/bohan/Documents/projects/denoising-diffusion-gan/saved_info/dd_gan/edges2shoes/ddgan_edges2shoes_bbdm_4_full/netG_225.pth', map_location=device)\n",
    "for key in list(ckpt.keys()):\n",
    "    ckpt[key[7:]] = ckpt.pop(key)\n",
    "netG.load_state_dict(ckpt)\n",
    "netG.eval()\n",
    "save_dir = \"./generated_samples/{}\".format('edges2shoes')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior_BBDM(x_0,x_t, y, t, T):\n",
    "    \n",
    "    def q_posterior_BBDM(x_0, x_t, y, t, T):\n",
    "        \n",
    "        \n",
    "        m_t = t / T\n",
    "        # m_t = torch.full((x_0.shape[0],), m_t, device=x_0.device)\n",
    "        m_t = m_t.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        # m_t_minus_one\n",
    "        m_t_minus_one = (t - 1) / T\n",
    "        # m_t_minus_one = torch.full((x_0.shape[0],), m_t_minus_one, device=x_0.device)\n",
    "        m_t_minus_one = m_t_minus_one.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        # delta_t and delta_t_minus_one\n",
    "        # delta_t = 2 * (m_t - m_t ** 2) + 1e-10\n",
    "        delta_t = t * (T - t) / T + 1e-10\n",
    "        # delta_t_minus_one = 2 * (m_t_minus_one - m_t_minus_one ** 2)\n",
    "        delta_t_minus_one = (t - 1) * (T - (t - 1)) / T\n",
    "        delta_t_by_t_minus_one = delta_t - delta_t_minus_one * ((1 - m_t) ** 2) / ((1 - m_t_minus_one) ** 2)\n",
    "        tilde_delta_t = delta_t_by_t_minus_one * delta_t_minus_one / delta_t\n",
    "\n",
    "        # c_xt, c_yt, and c_epst\n",
    "        c_xt = (delta_t_minus_one / delta_t) * (1 - m_t) / (1 - m_t_minus_one)\n",
    "        c_yt = m_t_minus_one - m_t * (1 - m_t) / (1 - m_t_minus_one) * (delta_t_minus_one / delta_t)\n",
    "        c_x0 = 1 - m_t_minus_one * delta_t_by_t_minus_one / delta_t\n",
    "\n",
    "\n",
    "\n",
    "        mean = (\n",
    "            c_xt * x_t + c_x0 * x_0 + c_yt * y\n",
    "        )\n",
    "        var = tilde_delta_t\n",
    "        return mean, var\n",
    "    \n",
    "  \n",
    "    def p_sample_BBDM(x_0, x_t, t, y, T):\n",
    "        mean, var = q_posterior_BBDM(x_0, x_t, y, t, T)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 1).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * (var ** 0.5) * noise\n",
    "            \n",
    "    sample_x_pos = p_sample_BBDM(x_0, x_t, t, y, T)\n",
    "    \n",
    "    return sample_x_pos\n",
    "\n",
    "def q_sample_BBDM(x_start, y, t, T):\n",
    "    t = t.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    m_t = t / T\n",
    "    # delta_t = 2 * (m_t - m_t ** 2)\n",
    "    delta_t = t * (T - t) / T\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    x_t = (1 - m_t) * x_start + m_t * y + delta_t ** 0.5 * noise\n",
    "    return x_t, m_t, delta_t\n",
    "\n",
    "def q_sample_pairs_for_BBDM(x_start, t, y, T):\n",
    "    assert y is not None, 'Condition is required for forward diffusion.'\n",
    "    x_t, m_t, delta_t = q_sample_BBDM(x_start, y, t, T)\n",
    "    tp1 = t + 1\n",
    "    tp1 = tp1.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    m_tp1 = tp1 / T\n",
    "    # delta_tp1 = 2 * (m_tp1 - m_tp1** 2)\n",
    "    delta_tp1 = m_tp1 * (T - m_tp1) / T + 1e-10\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    delta_tp1_given_t = delta_tp1 - delta_t * ((1 - m_tp1) ** 2 / (1 - m_t) ** 2)\n",
    "    c_x = (1 - m_tp1) / (1 - m_t)\n",
    "    c_y = m_tp1 - m_t * ((1 - m_tp1) / (1 - m_t))\n",
    "    x_tp1 = c_x * x_t + c_y * y + delta_tp1_given_t ** 0.5 * noise\n",
    "    return x_t, x_tp1\n",
    "\n",
    "def sample_from_model_BBDM(generator, n_time, x_init, opt, y):\n",
    "    x_t = x_init\n",
    "    x_steps = [x_t.clone()]\n",
    "    with torch.no_grad():\n",
    "        for i in reversed(range(1 , n_time)):\n",
    "            t = torch.full((x_t.size(0),), i, dtype=torch.int64).to(x_t.device)\n",
    "            latent_z = torch.randn(1, opt.nz, device=x_t.device)\n",
    "            x_0 = generator(x_t, t, latent_z)\n",
    "            x_new = sample_posterior_BBDM(x_0, x_t, y, t, args.num_timesteps)\n",
    "            x_t = x_new.detach()\n",
    "            x_steps.append(x_t.clone())\n",
    "\n",
    "    return x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "nz = args.nz\n",
    "x_t, y = dataset[32]\n",
    "real_y = y.to(device=\"cuda:0\")\n",
    "real_x = x_t.to(device=\"cuda:0\")\n",
    "\n",
    "real_test_x = real_x.unsqueeze(0)\n",
    "real_test_y = real_y.unsqueeze(0)\n",
    "\n",
    "# 0 1 2 3\n",
    "for i in range(0, args.num_timesteps):\n",
    "    print(i)\n",
    "    t = torch.full((1,), i, device=device)\n",
    "    x_t, x_tp1 = q_sample_pairs_for_BBDM(real_test_x, t, real_test_y, args.num_timesteps)  \n",
    "    assert not torch.isnan(x_t).any(), \"NaN detected in x_t\"\n",
    "    assert not torch.isnan(x_tp1).any(), \"NaN detected in x_t\"\n",
    "    latent_z = torch.randn(1, nz,device=device)       \n",
    "    x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "    assert not torch.isnan(x_tp1).any(), \"NaN detected in x_0_predict\"\n",
    "    x_pos_sample = sample_posterior_BBDM(x_0_predict, x_tp1, real_y, t + 1, args.num_timesteps)\n",
    "    use_real = sample_posterior_BBDM(real_test_x, x_tp1, real_y, t + 1, args.num_timesteps)\n",
    "    assert not torch.isnan(x_pos_sample).any(), \"NaN detected in x_pos_sample\"\n",
    "    resut = torch.cat([real_test_x, real_test_y, x_t, x_tp1, x_0_predict, x_pos_sample, use_real])\n",
    "    torchvision.utils.save_image(resut, os.path.join(save_dir, 'xresultt_t_{}_epoch{}.png'.format(i, 1)), normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddgan_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
