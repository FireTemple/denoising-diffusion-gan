{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets_prep.edges2shoes import Edge2Shoes\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset = Edge2Shoes(\"/mnt/c/Users/Public/Documents/Datasets/edge2shoes\", 4, 32, device=\"cuda:0\", split=\"train\")\n",
    "# 获取一个批次的数据\n",
    "x_t, y = dataset[45]\n",
    "print(x_t.shape)\n",
    "print(y.shape)\n",
    "# 打印图像和标签\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# 显示图像\n",
    "imshow(x_t)\n",
    "imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample_BBDM(x_start, y, t, T, noise=None):\n",
    "    m_t = t / T\n",
    "    m_t = m_t.unsqueeze(1).unsqueeze(2)\n",
    "    delta_t = 2 * (m_t - m_t ** 2)\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    # print(f\"xstart shape: {x_start.shape}\")\n",
    "    # print(f\"y shape: {y.shape}\")\n",
    "    # print(f\"t_menus_1 shape: {t_menus_1.shape}\")\n",
    "    # print(f\"delta_t_menus_1 shape: {delta_t_menus_1.shape}\")\n",
    "    x_t = (1 - m_t) * x_start + m_t * y + delta_t ** 0.5 * noise\n",
    "    return x_t, m_t, delta_t\n",
    "\n",
    "def q_sample_pairs_for_BBDM(x_start, y ,t_menus_1,T):\n",
    "\n",
    "    assert y is not None, 'Condition is required for forward diffusion.'\n",
    "    x_t_menus_1, m_t_menus_1, delta_t_menus_1 = q_sample_BBDM(x_start, y, t_menus_1, T)\n",
    "    t = t_menus_1 + 1\n",
    "    print(f\"t:{t}\")\n",
    "    m_t = t / T\n",
    "    m_t = m_t.unsqueeze(1).unsqueeze(2)\n",
    "    delta_t = 2 * (m_t - m_t** 2)\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    # print(\"===============\")\n",
    "    # print(f\"xstart shape: {x_start.shape}\")\n",
    "    # print(f\"y shape: {y.shape}\")\n",
    "    # print(f\"t shape: {t.shape}\")\n",
    "    # print(f\"delta_t shape: {delta_t.shape}\")\n",
    "    x_t = ((1 - m_t) / (1 - m_t_menus_1)) * x_t_menus_1 + (m_t - m_t_menus_1 * ((1 - m_t) / (1 - m_t_menus_1))) * y + (delta_t - delta_t_menus_1 * ((1 - m_t) ** 2 / (1 - m_t_menus_1) ** 2)) ** 0.5 * noise\n",
    "    return x_t_menus_1, x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "real_x = x_t.to(device, non_blocking=True)\n",
    "real_y = y.to(device, non_blocking=True)\n",
    "num_timesteps = 4\n",
    "\n",
    "forward_process = [real_x.cpu()]\n",
    "for i_menues_1 in range(0, num_timesteps):\n",
    "    i_menues_1 = torch.tensor([i_menues_1], device=real_x.device)\n",
    "    x_t, x_t = q_sample_pairs_for_BBDM(real_x, real_y, i_menues_1,num_timesteps)\n",
    "    # if i_menues_1 % 100 == 0:\n",
    "    #     print(i_menues_1)\n",
    "    #     forward_process.append(x_t.cpu().detach())    \n",
    "    forward_process.append(x_t.cpu().detach()) \n",
    "\n",
    "forward_process.append(x_t.cpu().detach())\n",
    "\n",
    "t = torch.tensor([0], device=real_x.device)\n",
    "x_t, x_t = q_sample_pairs_for_BBDM(real_x, real_y, t,num_timesteps)\n",
    "# imshow(x_t)\n",
    "# imshow(x_t_menus_1)\n",
    "# print(x_t)\n",
    "# print(x_t_menus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(forward_process))\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i_menues_1, image in enumerate(forward_process):\n",
    "    img = image / 2 + 0.5  # unnormalize\n",
    "    np_image = img.cpu().numpy()\n",
    "    ax = plt.subplot(1, len(forward_process), i_menues_1 + 1)  \n",
    "    ax.imshow(np.transpose(np_image, (1, 2, 0)))\n",
    "    if(i_menues_1 == 0):\n",
    "        ax.set_xlabel(f\"original img\")   \n",
    "    else:\n",
    "        ax.set_xlabel(f\"t = {1000 - i_menues_1 * 100}\")  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterio_BBDM(x_0,x_t, y, t, T):\n",
    "    # print(x_0.shape)\n",
    "    # print(x_t.shape)\n",
    "    # print(y.shape)\n",
    "    # print(t)\n",
    "    # print(\"========\")\n",
    "    def q_posterior_BBDM(x_0, x_t, y, t, T):\n",
    "\n",
    "        m_t = t / T\n",
    "        # m_t = torch.tensor([m_t], device=x_0.device)\n",
    "        # m_t = m_t.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # m_t_minus_one\n",
    "        m_t_minus_one = (t-1) / T\n",
    "        # m_t_minus_one = torch.tensor([m_t_minus_one], device=x_0.device)\n",
    "        # m_t_minus_one = m_t_minus_one.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # delta_t and delta_t_minus_one\n",
    "        delta_t = 2 * (m_t - m_t ** 2)\n",
    "        delta_t_minus_one = 2 * (m_t_minus_one - m_t_minus_one ** 2)\n",
    "        delta_t_by_t_minus_one = delta_t - delta_t_minus_one * ((1 - m_t) ** 2) / ((1 - m_t_minus_one) ** 2)\n",
    "        tilde_delta_t = delta_t_by_t_minus_one * delta_t_minus_one / delta_t\n",
    "\n",
    "        # c_xt, c_yt, and c_epst\n",
    "        c_xt = (delta_t_minus_one / delta_t) * (1 - m_t) / (1 - m_t_minus_one)\n",
    "        c_yt = m_t_minus_one - m_t * (1 - m_t) / (1 - m_t_minus_one) * (delta_t_minus_one / delta_t)\n",
    "        c_x0 = 1 - m_t_minus_one * delta_t_by_t_minus_one / delta_t\n",
    "\n",
    "\n",
    "\n",
    "        mean = (\n",
    "            c_xt * x_t + c_x0 * x_0 + c_yt * y\n",
    "        )\n",
    "        var = tilde_delta_t\n",
    "        return mean, var\n",
    "    \n",
    "  \n",
    "    def p_sample_BBDM(x_0, x_t, y, t, T):\n",
    "        mean, var = q_posterior_BBDM(x_0, x_t, y, t, T)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 1).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * torch.exp(0.5 * var) * noise\n",
    "            \n",
    "    sample_x_pos = p_sample_BBDM(x_0, x_t, y, t, T)\n",
    "    \n",
    "    return sample_x_pos\n",
    "\n",
    "def sample_from_model_BBDM(x_0, n_time, x_init, y):\n",
    "    x = x_init\n",
    "    x_steps = []\n",
    "    # x_steps.append(x_init)\n",
    "    with torch.no_grad():\n",
    "        for i in reversed(range(1 , n_time)):\n",
    "            t = torch.tensor([i], device=real_x.device)\n",
    "            print(t)\n",
    "            # latent_z = torch.randn([opt.nz], device=x.device)\n",
    "            x_new = sample_posterio_BBDM(x_0, x, y, t, n_time)\n",
    "            x_steps.append(x_new)\n",
    "            x = x_new.detach()\n",
    "    return x, x_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_sample, x_steps = sample_from_model_BBDM(real_x, num_timesteps, real_y, real_y)\n",
    "print(fake_sample.shape)\n",
    "print(len(x_steps))\n",
    "for i in range(len(x_steps)):\n",
    "    # print(x_steps[i].shape)\n",
    "    imshow(x_steps[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_sde.models.ncsnpp_generator_adagn import NCSNpp\n",
    "from argparse import Namespace\n",
    "\n",
    "# 手动创建 args 对象\n",
    "args = Namespace(\n",
    "    seed=1024,\n",
    "    resume=True,\n",
    "    image_size=32,\n",
    "    num_channels=3,\n",
    "    centered=True,\n",
    "    use_geometric=False,\n",
    "    beta_min=0.1,\n",
    "    beta_max=20.0,\n",
    "    num_channels_dae=128,\n",
    "    n_mlp=4,\n",
    "    ch_mult=[1, 2, 2, 2],\n",
    "    num_res_blocks=2,\n",
    "    attn_resolutions=(16,),\n",
    "    dropout=0.0,\n",
    "    resamp_with_conv=True,\n",
    "    conditional=True,\n",
    "    fir=True,\n",
    "    fir_kernel=[1, 3, 3, 1],\n",
    "    skip_rescale=True,\n",
    "    resblock_type='biggan',\n",
    "    progressive='none',\n",
    "    progressive_input='residual',\n",
    "    progressive_combine='sum',\n",
    "    embedding_type='positional',\n",
    "    fourier_scale=16.0,\n",
    "    not_use_tanh=False,\n",
    "    exp='ddgan_edges2shoes_4_full',\n",
    "    dataset='edges2shoes',\n",
    "    nz=100,\n",
    "    num_timesteps=4,\n",
    "    z_emb_dim=256,\n",
    "    t_emb_dim=256,\n",
    "    batch_size=1,\n",
    "    num_epoch=1000,\n",
    "    ngf=64,\n",
    "    lr_g=0.00016,\n",
    "    lr_d=0.000125,\n",
    "    beta1=0.5,\n",
    "    beta2=0.9,\n",
    "    no_lr_decay=False,\n",
    "    use_ema=True,\n",
    "    ema_decay=0.9999,\n",
    "    r1_gamma=0.02,\n",
    "    lazy_reg=15,\n",
    "    save_content=True,\n",
    "    save_content_every=50,\n",
    "    save_ckpt_every=25,\n",
    "    num_proc_node=1,\n",
    "    num_process_per_node=1,\n",
    "    node_rank=0,\n",
    "    local_rank=0,\n",
    "    master_address='127.0.0.1',\n",
    "    world_size=1\n",
    ")\n",
    "\n",
    "# 使用手动创建的 args 对象\n",
    "print(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior_BBDM(x_0,x_t, y, t, T):\n",
    "    \n",
    "    def q_posterior_BBDM(x_0, x_t, y, t, T):\n",
    "        \n",
    "        \n",
    "        m_t = t / T\n",
    "        # m_t = torch.full((x_0.shape[0],), m_t, device=x_0.device)\n",
    "        m_t = m_t.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        # m_t_minus_one\n",
    "        m_t_minus_one = (t - 1) / T\n",
    "        # m_t_minus_one = torch.full((x_0.shape[0],), m_t_minus_one, device=x_0.device)\n",
    "        m_t_minus_one = m_t_minus_one.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        # delta_t and delta_t_minus_one\n",
    "        delta_t = 2 * (m_t - m_t ** 2) + 1e-10\n",
    "        delta_t_minus_one = 2 * (m_t_minus_one - m_t_minus_one ** 2)\n",
    "        delta_t_by_t_minus_one = delta_t - delta_t_minus_one * ((1 - m_t) ** 2) / ((1 - m_t_minus_one) ** 2)\n",
    "        tilde_delta_t = delta_t_by_t_minus_one * delta_t_minus_one / delta_t\n",
    "\n",
    "        # c_xt, c_yt, and c_epst\n",
    "        c_xt = (delta_t_minus_one / delta_t) * (1 - m_t) / (1 - m_t_minus_one)\n",
    "        c_yt = m_t_minus_one - m_t * (1 - m_t) / (1 - m_t_minus_one) * (delta_t_minus_one / delta_t)\n",
    "        c_x0 = 1 - m_t_minus_one * delta_t_by_t_minus_one / delta_t\n",
    "\n",
    "\n",
    "\n",
    "        mean = (\n",
    "            c_xt * x_t + c_x0 * x_0 + c_yt * y\n",
    "        )\n",
    "        var = tilde_delta_t\n",
    "        return mean, var\n",
    "    \n",
    "  \n",
    "    def p_sample_BBDM(x_0, x_t, t, y, T):\n",
    "        mean, var = q_posterior_BBDM(x_0, x_t, y, t, T)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 1).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * (var ** 0.5) * noise\n",
    "            \n",
    "    sample_x_pos = p_sample_BBDM(x_0, x_t, t, y, T)\n",
    "    \n",
    "    return sample_x_pos\n",
    "\n",
    "def q_sample_BBDM(x_start, y, t, T):\n",
    "    t = t.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    m_t = t / T\n",
    "    delta_t = 2 * (m_t - m_t ** 2)\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    x_t = (1 - m_t) * x_start + m_t * y + delta_t ** 0.5 * noise\n",
    "    return x_t, m_t, delta_t\n",
    "\n",
    "def q_sample_pairs_for_BBDM(x_start, t, y, T):\n",
    "    assert y is not None, 'Condition is required for forward diffusion.'\n",
    "    x_t, m_t, delta_t = q_sample_BBDM(x_start, y, t, T)\n",
    "    tp1 = t + 1\n",
    "    tp1 = tp1.unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    m_tp1 = tp1 / T\n",
    "    delta_tp1 = 2 * (m_tp1 - m_tp1** 2)\n",
    "    noise = torch.rand_like(x_start, device=x_start.device)\n",
    "    delta_tp1_given_t = delta_tp1 - delta_t * ((1 - m_tp1) ** 2 / (1 - m_t) ** 2)\n",
    "    c_x = (1 - m_tp1) / (1 - m_t)\n",
    "    c_y = m_tp1 - m_t * ((1 - m_tp1) / (1 - m_t))\n",
    "    x_tp1 = c_x * x_t + c_y * y + delta_tp1_given_t ** 0.5 * noise\n",
    "    return x_t, x_tp1\n",
    "\n",
    "def sample_from_model_BBDM(generator, n_time, x_init, opt, y):\n",
    "    x_t = x_init\n",
    "    x_steps = [x_t.clone()]\n",
    "    with torch.no_grad():\n",
    "        for i in reversed(range(1 , n_time)):\n",
    "            t = torch.full((x_t.size(0),), i, dtype=torch.int64).to(x_t.device)\n",
    "            latent_z = torch.randn(1, opt.nz, device=x_t.device)\n",
    "            x_0 = generator(x_t, t, latent_z)\n",
    "            x_new = sample_posterior_BBDM(x_0, x_t, y, t, args.num_timesteps)\n",
    "            x_t = x_new.detach()\n",
    "            x_steps.append(x_t.clone())\n",
    "\n",
    "    return x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets_prep.edges2shoes import Edge2Shoes\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dataset = Edge2Shoes(\"/mnt/c/Users/Public/Documents/Datasets/edge2shoes\", 1, 32, device=\"cuda:0\", split=\"train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "device = \"cuda:0\"\n",
    "netG = NCSNpp(args).to(device)\n",
    "ckpt = torch.load('/mnt/c/Users/bohan/Documents/projects/denoising-diffusion-gan/saved_info/dd_gan/edges2shoes/ddgan_edges2shoes_bbdm_4_full/netG_225.pth', map_location=device)\n",
    "for key in list(ckpt.keys()):\n",
    "    ckpt[key[7:]] = ckpt.pop(key)\n",
    "netG.load_state_dict(ckpt)\n",
    "netG.eval()\n",
    "save_dir = \"./generated_samples/{}\".format('edges2shoes')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "nz = args.nz\n",
    "x_t, y = dataset[32]\n",
    "real_y = y.to(device=\"cuda:0\")\n",
    "real_x = x_t.to(device=\"cuda:0\")\n",
    "\n",
    "real_test_x = real_x.unsqueeze(0)\n",
    "real_test_y = real_y.unsqueeze(0)\n",
    "\n",
    "# 0 1 2 3\n",
    "for i in range(0, args.num_timesteps):\n",
    "    print(i)\n",
    "    t = torch.full((1,), i, device=device)\n",
    "    x_t, x_tp1 = q_sample_pairs_for_BBDM(real_test_x, t, real_test_y, args.num_timesteps)  \n",
    "    assert not torch.isnan(x_t).any(), \"NaN detected in x_t\"\n",
    "    assert not torch.isnan(x_tp1).any(), \"NaN detected in x_t\"\n",
    "    latent_z = torch.randn(1, nz,device=device)       \n",
    "    x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "    assert not torch.isnan(x_tp1).any(), \"NaN detected in x_0_predict\"\n",
    "    x_pos_sample = sample_posterior_BBDM(x_0_predict, x_tp1, real_y, t + 1, args.num_timesteps)\n",
    "    use_real = sample_posterior_BBDM(real_test_x, x_tp1, real_y, t + 1, args.num_timesteps)\n",
    "    assert not torch.isnan(x_pos_sample).any(), \"NaN detected in x_pos_sample\"\n",
    "    resut = torch.cat([real_test_x, real_test_y, x_t, x_tp1, x_0_predict, x_pos_sample, use_real])\n",
    "    torchvision.utils.save_image(resut, os.path.join(save_dir, 'xresultt_t_{}_epoch{}.png'.format(i, 1)), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_T = real_y\n",
    "# fake_sample = sample_from_model_BBDM(netG, args.num_timesteps, x_T, args, real_y)\n",
    "# torchvision.utils.save_image(fake_sample, os.path.join(save_dir, 'fake_sample_epoch_{}.png'.format(1)), normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
